1. AMD GPUs also have some kind of software support now -- https://blog.mlc.ai/2023/08/09/Making-AMD-GPUs-competitive-for-LLM-inference. Check diff between MLC and TVM
2. du -sh .[!.]* * -- to get size of all files
3. diff between PATH, LD_LIBRARY_PATH, C_INCLUDE_PATH and CPLUS_INLCUDE_PATH, CPLU_PATH, C_PATH
4. yum list installed | grep <package name> -- for finding installed packages on the system
5. TVM compiler, MLC, xla, triton
6. mlir, relay -- ir representation
7. it is possible to get module not found error even if the module is present and running it individually with python works. ensure to have all the versions compatible with each other.
8. 
